<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">

  <title>reactiveEmbeddedProgramming</title>

  <meta name="description" content="A framework for easily creating beautiful presentations using HTML">
  <meta name="author" content="Hakim El Hattab">

  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <link rel="stylesheet" href="libs/reveal.js/4.3.1/reset.css">
  <link rel="stylesheet" href="libs/reveal.js/4.3.1/reveal.css">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">

  <!-- highlight Theme -->
  
  <link rel="stylesheet" href="libs/highlight.js/11.3.1/styles/github.min.css">
  
	
		
	<link rel="stylesheet" href="libs/reveal.js/4.3.1/plugin/chalkboard/style.css">
	
	
	
	



  <!-- Revealjs Theme -->
  
  <link rel="stylesheet" href="libs/reveal.js/4.3.1/theme/white.css" id="theme">
  
  

  <link rel="stylesheet" href="libs/styles/tasklist.css">
	<link rel="stylesheet" href="libs/styles/iota.css">
	<link rel="stylesheet" href="libs/styles/layout.css">


  <!-- Revealjs Theme -->
  

   <!-- css list -->
	

   

</head>

<body>

   

  <div class="reveal">

    <!-- Any section element inside of this container is displayed as a slide -->
    <div class="slides">

      


    
        <section >
            
            <img src="./images/titlecard.png" alt="titlecard"/>
<aside class="notes"> intro - interrupt with questions - baremetal embedded architecture - several mixed examples, confusing - pseudo code</aside>

            </section>
    



    
        <section >
            
            <h4><code>aboutMe</code></h4>
<ul>
<li>embedded design</li>
<li>audio</li>
<li>baremetal</li>
<li>real time</li>
</ul>
<aside class="notes"> embedded design 15 years - audio industry - specialise in baremetal, no OS - real time</aside>

            </section>
    



    
        <section >
            
            <h4><code>reactive?</code></h4>
<aside class="notes"> What exactly do I mean when I say reactive?</aside>

            </section>
    



    
        <section >
            
            <h4><code>reactive?</code></h4>
<ul>
<li>polling vs callbacks - async</li>
</ul>
<aside class="notes"> system design - callbacks - events</aside>

            </section>
    



    
        <section >
            
            <h4><code>reactive?</code></h4>
<ul>
<li>polling vs callbacks - async</li>
<li>power, cpu time efficiency</li>
</ul>
<aside class="notes"> cpu efficiency - power efficiency - only do work when there’s work to do</aside>

            </section>
    



    
        <section >
            
            <h4><code>reactive?</code></h4>
<ul>
<li>polling vs callbacks - async</li>
<li>power, cpu time efficiency</li>
<li><code>-Odev</code></li>
</ul>
<aside class="notes"> easy to reason about - predictable timing - keep things simple</aside>

            </section>
    



    
        <section >
            
            <h4><code>part1::backgroundLoop</code></h4>
<aside class="notes"> look at regular polling architecture - background loop - superloop - common, proven architecture</aside>

            </section>
    



    
        <section >
            
            <h4><code>arduino</code></h4>
<pre><code class="language-arduino">void setup() {
    // runs once at the start of the program
}

void loop() {
    // runs on every iteration of the background loop
}
</code></pre>
<aside class="notes"> sketches - blank sketch - setup runs first, initialisations - loop runs continuously, program logic</aside>

            </section>
    



    
        <section >
            
            <h4><code>arduino::cppEntryPoint</code></h4>
<pre><code data-line-numbers="|4|7|" class="language-cpp">int main() {
    init();         // arduino initialisations

    setup();        // user provided

    for (;;) {      // background loop
        loop();     // user provided

        // ... arduino background tasks
    }
}
</code></pre>
<aside class="notes"> step up stack - generated by toolchain - c++ entry point - infinite loop</aside>

            </section>
    



    
        <section >
            
            <h4><code>arduino::blinky</code></h4>
<pre><code data-line-numbers="|2-3|8|9|10|" class="language-arduino">void setup() {
    // initialize digital pin LED_BUILTIN as an output.
    pinMode(LED_BUILTIN, OUTPUT);
}

// the loop function runs over and over again forever
void loop() {
    digitalWrite(LED_BUILTIN, HIGH);  // turn the LED on
    delay(1000);                      // wait for a second
    digitalWrite(LED_BUILTIN, LOW);   // turn the LED off
    delay(1000);                      // wait for a second
}
</code></pre>
<aside class="notes"> Arduino’s basic blink-an-LED on the board program - setup, assign LED pin output- drive it high and low - loop, high, wait for a second then low, etc.</aside>

            </section>
    



    
        <section >
            
            <h4><code>arduino::blinky</code></h4>
<img src="./images/blinky.svg" alt="blinky" width="100%"/>
<aside class="notes"> intro timing diagrams - explain left side items</aside>

            </section>
    



    
        <section >
            
            <pre><code class="language-Cpp">void setup() {
    setupTaskA();
    setupTaskB();
    setupTaskC();
}

void loop() {
    taskA();
    taskB();
    taskC();
}
</code></pre>
<aside class="notes"> something a little more complex - multiple generic tasks</aside>

            </section>
    



    
        <section >
            
            <pre><code data-line-numbers="|2|3-5|" class="language-Cpp">void taskA() {
    if (dataPending()) {
        const auto data = getDataFromHardware();

        process(data);
    }

    // No data, do nothing.
}
</code></pre>
<aside class="notes"> Our tasks might look something like this. We’ll only actually do work if data has arrived or if there is work to do, which we check for first. Meaning that most of the time, when this task is run, it just checks and returns.</aside>

            </section>
    



    
        <section >
            
            <h4><code>inconsistentTiming</code></h4>
<aside class="notes"> Each iteration of the background loop and our tasks are going to consume a different amounts of CPU time, depending on whether each task actually has work to do. Best case, our timing will be somewhat inconsistent as each task has to wait for the previous one to complete before it runs. I’ll show you why that’s a problem.</aside>

            </section>
    



    
        <section >
            
            <h4><code>audioRx</code></h4>
<img src="./images/nooverflow/nooverflow_0.svg" alt="nooverflow_0" width="100%"/>
<aside class="notes"> audio receiver - i2s - peripheral - cpu</aside>

            </section>
    



    
        <section >
            
            <h4><code>audioRx</code></h4>
<img src="./images/nooverflow/nooverflow_1.svg" alt="nooverflow_1" width="100%"/>
<aside class="notes"> Here we’ve got an inter-IC sound peripheral bringing in samples from a converter or some digital audio source.</aside>

            </section>
    



    
        <section >
            
            <h4><code>audioRx</code></h4>
<img src="./images/nooverflow/nooverflow_2.svg" alt="nooverflow_2" width="100%"/>
<aside class="notes"> When the sample receive is complete, the sample is moved into a buffer …</aside>

            </section>
    



    
        <section >
            
            <h4><code>audioRx</code></h4>
<img src="./images/nooverflow/nooverflow_3.svg" alt="nooverflow_3" width="100%"/>
<aside class="notes"> … and the sample ready status flag is raised.</aside>

            </section>
    



    
        <section >
            
            <h4><code>audioRx</code></h4>
<img src="./images/nooverflow/nooverflow_4.svg" alt="nooverflow_4" width="100%"/>
<aside class="notes"> We happen to be checking that ready flag.</aside>

            </section>
    



    
        <section >
            
            <h4><code>audioRx</code></h4>
<img src="./images/nooverflow/nooverflow_5.svg" alt="nooverflow_5" width="100%"/>
<aside class="notes"> see flat high - reading buffer - side effects - clears buffer - ready for next sample</aside>

            </section>
    



    
        <section >
            
            <h4><code>audioRx</code></h4>
<img src="./images/nooverflow/nooverflow_6.svg" alt="nooverflow_6" width="100%"/>
<aside class="notes"> Next sample arrives.</aside>

            </section>
    



    
        <section >
            
            <h4><code>audioRx</code></h4>
<img src="./images/nooverflow/nooverflow_7.svg" alt="nooverflow_7" width="100%"/>
<aside class="notes"> And so on.</aside>

            </section>
    



    
        <section >
            
            <h4><code>!overflow</code></h4>
<img src="./images/nooverflow/nooverflow.svg" alt="nooverflow" width="100%"/>
<aside class="notes"> In this scenario all is well, we haven’t overflowed.</aside>

            </section>
    



    
        <section >
            
            <h4><code>audioRx</code></h4>
<img src="./images/overflow/overflow_0.svg" alt="overflow_0" width="100%"/>
<aside class="notes"> However, if we happen to be doing some other processing at the time …</aside>

            </section>
    



    
        <section >
            
            <h4><code>audioRx</code></h4>
<img src="./images/overflow/overflow_1.svg" alt="overflow_1" width="100%"/>
<aside class="notes"> … and take too long before we check the ready flag, the next sample arrives.</aside>

            </section>
    



    
        <section >
            
            <h4><code>audioRx</code></h4>
<img src="./images/overflow/overflow_2.svg" alt="overflow_2" width="100%"/>
<aside class="notes"> The next sample arrives …</aside>

            </section>
    



    
        <section >
            
            <h4><code>overflow</code></h4>
<img src="./images/overflow/overflow.svg" alt="overflow" width="100%"/>
<aside class="notes"> and overwrites the previous sample before we had a chance to read and process it. In this case, sample0 is lost forever and the overflow status flag is raised indicating the error.</aside>

            </section>
    



    
        <section >
            
            <h4><code>interrupts</code></h4>
<aside class="notes"> In a real system, we’d use interrupts to ensure our timing constraints are met.</aside>

            </section>
    



    
        <section >
            
            <h4><code>I²S</code></h4>
<img src="./images/i2sinterrupt/i2sinterrupt_0.svg" alt="i2sinterrupt_0" width="100%"/>
<aside class="notes"> Here, we’re our busy task is interrupted by the sample ready status flag. We read the sample from the buffer in the interrupt then go back to our busy task until the next sample is ready. This way never missing a sample.</aside>
<aside class="notes"> Here we’ve got our busy task taking up all our cpu time.</aside>

            </section>
    



    
        <section >
            
            <h4><code>I²S</code></h4>
<img src="./images/i2sinterrupt/i2sinterrupt_1.svg" alt="i2sinterrupt_1" width="100%"/>
<aside class="notes"> Our sample becomes ready …</aside>

            </section>
    



    
        <section >
            
            <h4><code>I²S</code></h4>
<img src="./images/i2sinterrupt/i2sinterrupt_2.svg" alt="i2sinterrupt_2" width="100%"/>
<aside class="notes"> And this time, we’ve subscribed to the sample ready event.</aside>

            </section>
    



    
        <section >
            
            <h4><code>I²S</code></h4>
<img src="./images/i2sinterrupt/i2sinterrupt_3.svg" alt="i2sinterrupt_3" width="100%"/>
<aside class="notes"> This event interrupts our execution of our busy loop while we read the sample, before returning to the busy loop.</aside>

            </section>
    



    
        <section >
            
            <h4><code>!overflow</code></h4>
<img src="./images/i2sinterrupt/i2sinterrupt.svg" alt="i2sinterrupt" width="100%"/>
<aside class="notes"> And so on for the other samples.</aside>

            </section>
    



    
        <section >
            
            <h4><code>interrupts</code></h4>
<pre><code data-line-numbers="|1-2|3|5-6|8-9|11|" class="language-Cpp">// Placed at specific address by linker.
extern &quot;C&quot; void handleI2sInterrupt() {
    const auto status = I2s::readInterruptStatus();

    if (status &amp; I2s::Status::notEmpty)
        fifo.push(I2s::readData());

    if (status &amp; I2s::Status::overflow)
        I2s::handleOverflowError();

    I2s::clearInterruptStatus();
}
</code></pre>
<aside class="notes"> An interrupt can be enabled at the hardware level which will cause the CPU to stop whatever it’s in the middle of, stash the current state and execute code at a specific address. The compiler’s linker will put your ISR function in the right spot. In this case we’d have subscribed to the input-buffer-not-empty and input-buffer-overflow interrupts, so when any of those events occur we’ll execute our ISR. Firstly checking why we’ve arrived here and dealing with each case.</aside>

            </section>
    



    
        <section >
            
            <pre><code class="language-Cpp">void exampleReceiverTask() {
    while (DataType data; fifo.pop(data)) {
        process(data);
    }

    // No more data, return.
}
</code></pre>
<aside class="notes"> Our task now (taskA?) running on the background loop, still checks for data, but it does so via our FIFO. The timing of this function may still be inconsistent, but it doesn’t matter as much because our hardware data handling is happening in interrupts.</aside>

            </section>
    



    
        <section >
            
            <h4><code>interrupts</code></h4>
<img src="./images/interrupt.svg" alt="interrupt" width="100%"/>
<aside class="notes"> This basic view of an interrupt shows essentially what happens when we get an interrupt.
The interrupt is triggered my an event of some kind, which we’ve enabled in hardware.
We pause execution wherever we are. Save our current CPU state and execute the function at a memory address specific to the interrupt triggered, whatever function is at that address will be run. Then when we exit that function, we’ll restore our previous state and continue. More on interrupts later.</aside>

            </section>
    



    
        <section >
            
            <h4><code>part2::scheduler</code></h4>
<aside class="notes"> We’re not really going to just stick all our processing in the background loop and continuously poll. We’ll get much more consistent timing if we check at a realistic frequency for each task.</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler</code></h4>
<pre><code class="language-Cpp">int main() {
    // initialisations
    setupTaskA();
    setupTaskB();
    setupTaskC();

    // background loop
    for (;;) {
        taskA();
        taskB();
        taskC();
    }
}
</code></pre>
<aside class="notes"> Let’s recreate this but with specific timing intervals.</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler</code></h4>
<pre><code data-line-numbers="|4|6-8|12|" class="language-Cpp">int main() {
    // ... task initialisations

    Scheduler::init(1ms);

    Scheduler::add(1ms, taskA);
    Scheduler::add(10ms, taskB);
    Scheduler::add(40ms, taskC); // (25Hz)

    // background loop
    for (;;) {
        Scheduler::run();
    }
}
</code></pre>
<aside class="notes"> We’ll initialise our scheduler, which we’ll look at in a minute. Then we’ll add our tasks, passing the functions in along with the specific timing. Then all we do in the background loop is call our run function which will run our functions at the requested times.
e.g. sensor processing
e.g. user interface
e.g. display refresh (25Hz)</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler</code></h4>
<pre><code class="language-Cpp">Scheduler::init(std::chrono::milliseconds res) {
    Timer::init(res);
    Timer::enableInterrupt(Int::update, Int::Priority::low);
}
</code></pre>
<aside class="notes"> The scheduler initialiser is going to setup a timer to update every millisecond, or whatever interval is required, with an interrupt to fire on each trigger.</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler</code></h4>
<pre><code class="language-Cpp">/// @returns `false` if scheduler is full, otherwise `true`.
bool Scheduler::add(std::chrono::milliseconds runEvery,
                    std::add_pointer_t&lt;void()&gt; function) {
    auto&amp; events = Scheduler::getEventsList();
    return events.add(runEvery, function);
}
</code></pre>
<aside class="notes"> The scheduler’s add function’s going to bung this information onto list of events, which will likely just be a fixed array, so it might be full. In this case we’re just getting a pointer to a static function, but you could use inplace_function here if you wanted something more versatile.</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler</code></h4>
<pre><code data-line-numbers="|4|5|7-9|" class="language-Cpp">extern &quot;C&quot; void timerInterruptHandler() {
    const auto status = Timer::readInterruptStatus();

    if (status &amp; Timer::Status::update) {
        auto&amp; events = Scheduler::getEventsList();

        for (int i = 0; i &lt; events.size(); ++i) {
            events[i].update();
        }
    }

    Timer::clearInterruptStatus();
}
</code></pre>
<aside class="notes"> Our timer interrupt is going to run every millisecond and in there we’ll just go through our list of events and update their counters.</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler</code></h4>
<pre><code data-line-numbers="|8|9|" class="language-Cpp">// called from background loop
void Scheduler::run() {
    auto&amp; events = Scheduler::getEventsList();

    for (int i = 0; i &lt; events.size(); ++i) {
        auto&amp; event = event[i];

        if (event.shouldRun())
            event.run();
    }
}
</code></pre>
<aside class="notes"> The scheduler run function is just going to go through the events and check the counter value against the timing value that we set earlier. <code>shouldRun()</code> will return true if enough time has passed since the last time we ran. Then when we call <code>run()</code> here, we’ll execute the task and internally it’ll reset its counter.</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler</code></h4>
<img src="./images/scheduler/scheduler_0.svg" alt="scheduler_0" width="100%"/>
            </section>
    



    
        <section >
            
            <h4><code>scheduler</code></h4>
<img src="./images/scheduler/scheduler_1.svg" alt="scheduler_1" width="100%"/>
<aside class="notes"> Here I’m showing each task running one at a time as we’re single cpu, and at each mark we’re running our scheduled tasks sequentially.
At 1ms after our scheduler is enabled, we’ll run all our tasks unless we setup it up so that everything starts at the next iteration, which might be wise. But for now we’ll just assume a naive implementation.</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler</code></h4>
<img src="./images/scheduler/scheduler_2.svg" alt="scheduler_2" width="100%"/>
<aside class="notes"> At 2ms, we’ll run task A again.</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler</code></h4>
<img src="./images/scheduler/scheduler_3.svg" alt="scheduler_3" width="100%"/>
<aside class="notes"> Skipping to 10ms taskB is triggerred.</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler</code></h4>
<img src="./images/scheduler/scheduler_4.svg" alt="scheduler_4" width="100%"/>
<aside class="notes"> And so on.</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler</code></h4>
<img src="./images/scheduler/scheduler.svg" alt="scheduler" width="100%"/>
<aside class="notes"> Eventually calling taskC.
Note that you could implement this staggered so that that taskB and taskC aren’t triggered on the same boundary, but again, assuming naive implementation here, just to keep things simple.</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler::bug</code></h4>
<img src="./images/scheduler/scheduler.svg" alt="scheduler" width="100%"/>
<aside class="notes"> Can we break this scheduler? Does this design have a flaw? What happens if one of these tasks takes longer than a millisecond to execute?
I once worked on a small project which was a quick-as-possible demo proof-of-concept side-project where we basically took an existing design and just scaled it up. Sounds simple enough, and seemed to be until we started running the thing and strange things started happening.</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler::bug</code></h4>
<aside class="notes"> brief tangent - worked on quick proof-of-concept project</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler::bug</code></h4>
<ul>
<li>legacy codebase</li>
</ul>
<aside class="notes"> take a legacy product - and code</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler::bug</code></h4>
<ul>
<li>legacy codebase</li>
<li>scale up - ‘make it bigger’</li>
</ul>
<aside class="notes"> the idea - what could possibly go wrong? - fun project</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler::bug</code></h4>
<ul>
<li>legacy codebase</li>
<li>scale up - ‘make it bigger’</li>
<li>strange behaviour</li>
</ul>
<aside class="notes"> buggy - unpredictable - long time to diagnose the issue</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler::bug</code></h4>
<img src="./images/scheduler_broken/scheduler_broken_0.svg" alt="scheduler_broken_0" width="100%"/>
<aside class="notes"> this is what happened - one process/task didn’t scale well</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler::bug</code></h4>
<img src="./images/scheduler_broken/scheduler_broken_1.svg" alt="scheduler_broken_1" width="100%"/>
<aside class="notes"> single cpu microcontroller - blocked</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler::bug</code></h4>
<img src="./images/scheduler_broken/scheduler_broken_2.svg" alt="scheduler_broken_2" width="100%"/>
            </section>
    



    
        <section >
            
            <h4><code>scheduler::bug</code></h4>
<img src="./images/scheduler_broken/scheduler_broken.svg" alt="scheduler_broken" width="100%"/>
<aside class="notes"> system still working - interrupts still serviced - incoming data at risk of overflowing - outputs at risk of starvation - timing all over the place - mysterious bugs</aside>

            </section>
    



    
        <section >
            
            <h4><code>possibleSolutions</code></h4>
<ul>
<li>larger buffers</li>
<li>split</li>
<li>real-time operating system (RTOS)</li>
</ul>
<aside class="notes"> larger buffers, block processing no data lost - split using state machine - freeRTOS</aside>

            </section>
    



    
        <section >
            
            <h4><code>possibleSolutions</code></h4>
<ul>
<li><s>larger buffers</s> &gt; latency</li>
<li>split</li>
<li>real-time operating system (RTOS)</li>
</ul>
<aside class="notes"> changes in latency</aside>

            </section>
    



    
        <section >
            
            <h4><code>possibleSolutions</code></h4>
<ul>
<li><s>larger buffers</s> &gt; latency</li>
<li><s>split</s> &gt; complexity</li>
<li>real-time operating system (RTOS)</li>
</ul>
<aside class="notes"> dev time - complexity - significantly longer exe time if run on timer - how to split unknown system without breaking</aside>

            </section>
    



    
        <section >
            
            <h4><code>possibleSolutions</code></h4>
<ul>
<li><s>larger buffers</s> &gt; latency</li>
<li><s>split</s> &gt; complexity</li>
<li><s>real-time operating system (RTOS)</s> &gt; footprint</li>
</ul>
<aside class="notes"> I didn’t feel that we had the memory footprint to add an real-time operating system, though thinking back, that would probably have been fine.
Anyway, those are my excuses and I’m sticking to them. We’re engineers, we could probably make any of these options work, but I went in a different direction.</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler::fix</code></h4>
<img src="./images/scheduler_fix/scheduler_fix_0.svg" alt="scheduler_fix_0" width="100%"/>
<aside class="notes"> What do I really want to happen here? - let taskC take time - pause for other tasks</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler::fix</code></h4>
<img src="./images/scheduler_fix/scheduler_fix_1.svg" alt="scheduler_fix_1" width="100%"/>
<aside class="notes"> At the 2ms mark, we’d pause taskC, run A and return to C.</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler::fix</code></h4>
<img src="./images/scheduler_fix/scheduler_fix.svg" alt="scheduler_fix" width="100%"/>
<aside class="notes"> Same again at 10 and 20ms - taskC take a little longer - preferable to delaying A and B - looks similar to interrupts</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler</code></h4>
<pre><code data-line-numbers="|6-8|" class="language-Cpp">int main() {
    // ... task initialisations

    Scheduler::init(1ms);

    Scheduler::add(1ms, taskA, Priority::high);
    Scheduler::add(10ms, taskB, Priority::high);
    Scheduler::add(40ms, taskC);

    // background loop
    for (;;) {
        Scheduler::run();
    }
}
</code></pre>
<aside class="notes"> pull this off - tell the scheduler priority</aside>

            </section>
    



    
        <section >
            
            <h4><code>scheduler</code></h4>
<pre><code data-line-numbers="|10-11|" class="language-Cpp">extern &quot;C&quot; void timerInterruptHandler() {
    const auto status = Timer::readInterruptStatus();

    if (status &amp; Timer::Status::update) {
        auto&amp; events = Scheduler::getEventsList();

        for (int i = 0; i &lt; events.size(); ++i) {
            events[i].update();

            if (event.shouldRun(Priority::high))
                event.run();
        }
    }
...
</code></pre>
<aside class="notes"> in our timer interrupt - specialised version of our shouldRun() - checks and then runs tasks which are high priority - executing here means executing in interrupt</aside>

            </section>
    



    
        <section >
            
            <h4><code>interrupts</code></h4>
<ul>
<li>short</li>
<li>fast</li>
<li>flags</li>
</ul>
<aside class="notes"> interrupts supposed to be - set a flag and return - can we do this?</aside>

            </section>
    



    
        <section >
            
            <h4><code>preemptiveInterrupts</code></h4>
<aside class="notes"> nowadays likely - interrupt controller - interrupts interrupting interrupts - priority based</aside>

            </section>
    



    
        <section >
            
            <h4><code>preemptiveInterrupts</code></h4>
<img src="./images/preemptive/preemptive_0.svg" alt="preemptive_0" width="100%"/>
            </section>
    



    
        <section >
            
            <h4><code>preemptiveInterrupts</code></h4>
<img src="./images/preemptive/preemptive_1.svg" alt="preemptive_1" width="100%"/>
            </section>
    



    
        <section >
            
            <h4><code>preemptiveInterrupts</code></h4>
<img src="./images/preemptive/preemptive_2.svg" alt="preemptive_2" width="100%"/>
            </section>
    



    
        <section >
            
            <h4><code>preemptiveInterrupts</code></h4>
<img src="./images/preemptive/preemptive_3.svg" alt="preemptive_3" width="100%"/>
            </section>
    



    
        <section >
            
            <h4><code>preemptiveInterrupts</code></h4>
<img src="./images/preemptive/preemptive.svg" alt="preemptive" width="100%"/>
            </section>
    



    
        <section >
            
            <h4><code>preemptiveInterrupts</code></h4>
<img src="./images/preemptive/preemptive_4.svg" alt="preemptive_4" width="100%"/>
<aside class="notes"> interrupts trigger at the same time - serviced in priority order - ARM NVIC - preemptive scheduler implemented in hardware</aside>

            </section>
    



    
        <section >
            
            <h4><code>interruptScheduler</code></h4>
<img src="./images/scheduler_fix/scheduler_fix.svg" alt="scheduler_fix" width="100%"/>
<aside class="notes"> If we look back at our timer-based scheduler…</aside>

            </section>
    



    
        <section >
            
            <h4><code>interruptScheduler</code></h4>
<img src="./images/scheduler_fix/scheduler_fix_2.svg" alt="scheduler_fix_2" width="100%"/>
<aside class="notes"> We’re able to achieve this by running task A and B in interrupt context.</aside>

            </section>
    



    
        <section >
            
            <h4><code>interruptPriority</code></h4>
<ul>
<li>hardware triggered interrupts</li>
<li>software/user triggered interrupts</li>
</ul>
<aside class="notes"> distinguish between - special consideration - hardware interrupts - hard real time</aside>

            </section>
    



    
        <section >
            
            <h4><code>interruptPriority</code></h4>
<pre><code>highPriority
˄   hardwareHigh
|   hardwareLow
|   softwareHigh
˅   softwareLow
lowPriority
</code></pre>
<aside class="notes"> hw interrupts precedence - split/group priorities - design system around timing constraints</aside>

            </section>
    



    
        <section >
            
            <h4><code>part3::reactive</code></h4>
<aside class="notes"> Where do we go from here. We’re already running most of the system in interrupts via our scheduler. What’s next?
I’m now going to move away from needing this scheduler. I want to use the interrupt controller as a scheduler that runs in hardware.</aside>

            </section>
    



    
        <section >
            
            <h4><code>I²S</code></h4>
<img src="./images/i2sinterrupt/i2sinterrupt.svg" alt="i2sinterrupt" width="100%"/>
<aside class="notes"> Looking back at the audio input system - I’m going to rearrange this a little so that our samples are being collected via dma.</aside>

            </section>
    



    
        <section >
            
            <h4><code>I²S</code></h4>
<img src="./images/i2sdma.svg" alt="i2sdma" width="100%"/>
<aside class="notes"> DMA gives our peripheral controller access to the memory bus, so it can push its data directly without us actually needing an interrupt to do it, then we can setup a DMA interrupt to alert us when we’re got a buffer of audio data ready to process.</aside>

            </section>
    



    
        <section >
            
            <h4><code>I²S</code></h4>
<img src="./images/coroutine/coroutine_0.svg" alt="coroutine_0" width="100%"/>
<aside class="notes"> Instead of a single sample, we’ve got this buffer coming in and an interrupt to tell us when it’s full.</aside>

            </section>
    



    
        <section >
            
            <h4><code>I²S</code></h4>
<img src="./images/coroutine/coroutine_1.svg" alt="coroutine_1" width="100%"/>
<aside class="notes"> In this interrupt we’ll tell the DMA to start filling another buffer, which leaves us with a nice buffer (bufferA) of audio data, ready to process.
Now, we could wait for our scheduled process function, e.g. 1ms function, to do our audio work, but I don’t want to do that. I’ve got the data, I’d like to handle it right now. I want to react to this data becoming available.</aside>

            </section>
    



    
        <section >
            
            <h4><code>I²S</code></h4>
<img src="./images/coroutine/coroutine.svg" alt="coroutine" width="100%"/>
<aside class="notes"> What I want is to schedule a software interrupt, from the hardware DMA interrupt. The software interrupt is going to be our version of an audio thread. This thread is high priority in terms of our software interrupts, but it must have a lower priority than our hardware interrupts. As such, even though we’re triggering this interrupt from the DMA interrupt here, it won’t actually run until the DMA interrupt is finished.</aside>

            </section>
    



    
        <section >
            
            <h4><code>pseudoCoroutine</code></h4>
<img src="./images/coroutine/coroutine.svg" alt="coroutine" width="100%"/>
<aside class="notes"> I’m going to refer to this software interrupt process as a pseudo coroutine.</aside>

            </section>
    



    
        <section >
            
            <h4><code>pseudoCoroutine</code></h4>
<pre><code data-line-numbers="|4|5-6|8-12|" class="language-Cpp">extern &quot;C&quot; void dmaInterruptHandler() {
    const auto status = Dma::readInterruptStatus();

    if (status &amp; Dma::Status::bufferFull) {
        Dma::swapBuffer();
        Dma::enable();

        Scheduler::execute(
            Scheduler::Priority::high,
            [buffer = Dma::getAltBuffer()]{
                Audio::process(buffer);
            });
    }
...
</code></pre>
<aside class="notes"> A possible example of what this might look like. If our buffer is full, swap for the alternate buffer and reenable the dma transfers. It may well be the case that you won’t need to actually do that yourself. I think STM32’s from F2 upwards have DMA’s which have double buffering built in, so that could be automatic.
Then we’ll schedule our coroutine to run and process the buffer that the DMA isn’t using. We’ll imagine that getAltBuffer returns a std::span or something like that, pointing to a static array.</aside>

            </section>
    



    
        <section >
            
            <h4><code>pseudoCoroutine</code></h4>
<pre><code data-line-numbers="|5-7|8|9-10|11|" class="language-Cpp">#include &lt;inplace_function.h&gt;

void Scheduler::execute(Scheduler::Priority priority,
                        stdext::inplace_function func) {
    auto timer = Timers::getAvailableTimer();

    if (timer.hasValue()) {
        timer-&gt;setInterruptFunction(func);
        timer-&gt;enableInterrupt(
            Scheduler::getInterruptProperty(priority));
        timer-&gt;enableOneShot(0); // interrupt now pending
    }
    else { /* error */ }
}
</code></pre>
<aside class="notes"> Then inside the execute function. Now bare in mind this definitely isn’t the only way to schedule an interrupt, this is just a method which might be quite simple to implement and doesn’t require any other processing, and usually there are plenty of timers to use. This is what I might call optimised for the developer.
We’re getting a timer from say a pool of timers, some system where we’re keeping track of our hardware timers. This might return a std::optional so we can check for errors.
We’ll set our function that we want to run when the timer interrupts and enable the timer interrupt with a translation of the priority - remember, a scheduler’s high priority won’t be the highest actual interrupt priority because we’ve still got hardware interrupts to worry about.
Then we’ll enable the timer in one-shot mode, so once it triggers it disables itself, and we’ll set the timer to time out right now, at which point the timer interrupt will be pending, waiting for this thread - which is a higher priority (hardware) thread - to finish.</aside>

            </section>
    



    
        <section >
            
            <h4><code>pseudoCoroutine</code></h4>
<pre><code data-line-numbers="|1-2|5-7|" class="language-Cpp">extern &quot;C&quot; void timer14InterruptHandler() {
    auto&amp; timer = Timers::getTimer(14);
    const auto status = timer.readInterruptStatus();

    if (status &amp; Timer::Status::update
            &amp;&amp; timer.intFunction) {
        timer.intFunction();
        timer.setInterruptFunction(null);
    }

    timer.clearInterruptStatus();
}
</code></pre>
<aside class="notes"> Let’s say in this case we got timer 14, once the DMA interrupt exits, we’ll enter timer 14’s interrupt handler, get the corresponding timer, then if the interrupt function is valid, run it.
You’d probably abstract some of that as every timer interrupt handler will want to do something similar, and you may want more safety checks.</aside>

            </section>
    



    
        <section >
            
            <h4><code>pseudoCoroutine</code></h4>
<img src="./images/reactive/reactive_0.svg" alt="reactive_0" width="100%"/>
<aside class="notes"> To quickly recap. Let’s say we’re running taskC, which is running at our lowest priority interrupt level.</aside>

            </section>
    



    
        <section >
            
            <h4><code>pseudoCoroutine</code></h4>
<img src="./images/reactive/reactive_1.svg" alt="reactive_1" width="100%"/>
<aside class="notes"> TaskC gets interrupted by a hardware interrupt. We’ve got some data for task A so the interrupt schedules taskA as its pseudo coroutine.
A schedules taskA</aside>

            </section>
    



    
        <section >
            
            <h4><code>pseudoCoroutine</code></h4>
<img src="./images/reactive/reactive_2.svg" alt="reactive_2" width="100%"/>
<aside class="notes"> TaskA gets going as soon as the hardware interrupt exits.</aside>

            </section>
    



    
        <section >
            
            <h4><code>pseudoCoroutine</code></h4>
<img src="./images/reactive/reactive_3.svg" alt="reactive_3" width="100%"/>
<aside class="notes"> TaskA gets interrupted by another hardware interrupt, this time with data for taskB, so taskB is scheduled but remains pending for now as taskA still has work to do and is a higher priority.</aside>

            </section>
    



    
        <section >
            
            <h4><code>pseudoCoroutine</code></h4>
<img src="./images/reactive/reactive.svg" alt="reactive" width="100%"/>
<aside class="notes"> As soon as taskA finishes, taskB can execute before dropping back to taskC.</aside>

            </section>
    



    
        <section >
            
            <h4><code>typicalScheduler</code></h4>
<pre><code data-line-numbers="" class="language-Cpp">int main() {
    // ... task initialisations

    Scheduler::init(1ms);

    Scheduler::add(1ms, taskA);
    Scheduler::add(10ms, taskB);
    Scheduler::add(40ms, taskC); // (25Hz)

    // background loop
    for (;;) {
        Scheduler::run();
    }
}
</code></pre>
<aside class="notes"> Now if we look back at our old scheduler…</aside>

            </section>
    



    
        <section >
            
            <h4><code>reactiveScheduler</code></h4>
<pre><code data-line-numbers="" class="language-Cpp">int main() {
    // Tasks will schedule their own pseudo-coroutines
    // or timer interrupts.
    setupTaskA();
    setupTaskB();
    setupTaskC();

    // background loop
    for (;;) {
        // sleep
        asm volatile(&quot;wfi&quot;);    // &quot;wait for interrupt&quot;
    }
}
</code></pre>
<aside class="notes"> We don’t really need that scheduler here any more as we’re letting our various tasks schedule their own timer-based coroutines.
Our background loop no longer needs to do anything, so it can just sleep. This wfi instruction is an ARM instruction which puts the CPU into low-power mode, ready to be woken by an interrupt.
Each time we interrupt, we’ll come back here, iterate the loop and go back to sleep.
We could do other things in here such as count the amount of time that the system is idle, rudimentary benchmarking.
Or we could even get rid of the background loop entirely.</aside>

            </section>
    



    
        <section >
            
            <blockquote>
<p>“If the SLEEPONEXIT bit of the SCR is set to 1, when the processor completes the execution of an exception handler, it returns to Thread mode and immediately enters sleep mode. Use this mechanism in applications that only require the processor to run when an exception occurs.” - PM0214, 2012</p>
</blockquote>
<aside class="notes"> Here’s a quote from the datasheet. Exception handler is datasheet speak for interrupt, thread mode just meaning normal executions outside of interrupt.</aside>

            </section>
    



    
        <section >
            
            <h4><code>backgroundLess</code></h4>
<pre><code data-line-numbers="" class="language-Cpp">int main() {
    // Tasks will schedule their own pseudo-coroutines
    // or timer interrupts.
    setupTaskA();
    setupTaskB();
    setupTaskC();

    // Enable Cortex-M SLEEPONEXIT mode by writing a '1'
    // to System Control Register bit 1.
    // i.e. sleep unless in interrupt
    SCB-&gt;SCR |= (1u &lt;&lt; 1);
}
</code></pre>
<aside class="notes"> Cortex M devices have a handy feature where you can tell the CPU to sleep unless it’s running an interrupt, saving us from returning to an empty main function.</aside>

            </section>
    



    
        <section >
            
            <h4><code>wrapUp</code></h4>
<aside class="notes"> why do this or when should you use this? No hard set rules</aside>

            </section>
    



    
        <section >
            
            <h4><code>wrapUp</code></h4>
<ul>
<li>timing</li>
</ul>
<aside class="notes"> reason about, priorities, counting in bg, lots of tasks/threads</aside>

            </section>
    



    
        <section >
            
            <h4><code>wrapUp</code></h4>
<ul>
<li>timing</li>
<li>lightweight</li>
</ul>
<aside class="notes"> lightweight compared to a full rtos, done in hardware</aside>

            </section>
    



    
        <section >
            
            <h4><code>wrapUp</code></h4>
<ul>
<li>timing</li>
<li>lightweight</li>
<li>interesting alternative</li>
</ul>
<aside class="notes"> nothing wrong with other approaches, learning tool</aside>

            </section>
    



    
        <section >
            
            <h4><code>wrapUp</code></h4>
<ul>
<li>timing</li>
<li>lightweight</li>
<li>interesting alternative</li>
</ul>

            </section>
    



    
        <section >
            
            <h4><code>wrapUp</code></h4>
<ul>
<li>timing</li>
<li>lightweight</li>
<li>interesting alternative</li>
<li>nordic softdevice</li>
</ul>
<aside class="notes"> possible other systems</aside>

            </section>
    



    
        <section >
            
            <h4><code>wrapUp</code></h4>
<ul>
<li>timing</li>
<li>lightweight</li>
<li>interesting alternative</li>
<li>nordic softdevice</li>
<li>reliability</li>
</ul>
<aside class="notes"> most important thing - structure project by importance - if there’s something that must not fail, put it on top</aside>

            </section>
    



    
        <section >
            
            <h4><code>wrapUp</code></h4>
<ul>
<li>timing</li>
<li>lightweight</li>
<li>interesting alternative</li>
<li>nordic softdevice</li>
<li>reliability</li>
<li>in production</li>
</ul>
<aside class="notes"> if you trust your hardware</aside>

            </section>
    



    
        <section >
            
            <h4><code>caveats</code></h4>
<aside class="notes"> things to know</aside>

            </section>
    



    
        <section >
            
            <h4><code>caveats</code></h4>
<ul>
<li>preemptive</li>
</ul>
<aside class="notes"> must be able to interrupt itself - structure - priorities</aside>

            </section>
    



    
        <section >
            
            <h4><code>caveats</code></h4>
<ul>
<li>preemptive</li>
<li>timers</li>
</ul>
<aside class="notes"> lots of timers in example - other ways - crect use interrupt vector table</aside>

            </section>
    



    
        <section >
            
            <h4><code>caveats</code></h4>
<ul>
<li>preemptive</li>
<li>timers</li>
<li>security</li>
</ul>
<aside class="notes"> interrupts = elevated privileges</aside>

            </section>
    



    
        <section >
            
            <h4><code>caveats</code></h4>
<ul>
<li>preemptive</li>
<li>timers</li>
<li>security</li>
<li>timing</li>
</ul>
<aside class="notes"> timing consequences</aside>

            </section>
    



    
        <section >
            
            <h4><code>caveats</code></h4>
<ul>
<li>preemptive</li>
<li>timers</li>
<li>security</li>
<li>timing</li>
<li>synchronising</li>
</ul>
<aside class="notes"> sharing data</aside>

            </section>
    



    
        <section >
            
            <h4><code>caveats</code></h4>
<ul>
<li>preemptive</li>
<li>timers</li>
<li>security</li>
<li>timing</li>
<li>synchronising</li>
<li>cortex-m0 / ARMv6-M</li>
</ul>
<aside class="notes"> stm32G0 4 priorities - ARMv6-M no exclusive load/store</aside>

            </section>
    



    
        <section >
            
            <h4><code>furtherReading</code></h4>
<p>emBO++ 2018 - Emil Fresk: crect the compile time, reactive scheduler</p>
<p>Fabian Renn-Giles &amp; Dave Rowland - Real-time 101</p>
<p>pendSV</p>

            </section>
    



    
        <section >
            
            <h4><code>reactiveEmbeddedProgramming</code></h4>
<ul>
<li>diagrams made using <a href="http://wavedrom.com/editor">wavedrom.com/editor</a></li>
<li>concepts tested on STM32 single core microcontrollers</li>
<li>thanks to ADC for having me</li>
<li>thank you for listening</li>
<li><a href="http://github.com/baremetaldev">github.com/baremetaldev</a></li>
<li>baremetal.dev … coming soon</li>
</ul>

            </section>
    



    
    <section>
        <section >
            <h4><code>bonus::synchronising</code></h4>

            </section>
        
            <section >
                <h4><code>bonus::synchronising</code></h4>
<ul>
<li>volatile?</li>
</ul>

            </section>
        
            <section >
                <h4><code>bonus::synchronising</code></h4>
<ul>
<li><s>volatile?</s></li>
</ul>

            </section>
        
            <section >
                <h4><code>bonus::synchronising</code></h4>
<ul>
<li><s>volatile?</s></li>
<li>atomic_T / std::atomic<T>?</li>
</ul>

            </section>
        
            <section >
                <h4><code>bonus::synchronising</code></h4>
<ul>
<li><s>volatile?</s></li>
<li>atomic_T / std::atomic<T></li>
</ul>

            </section>
        
            <section >
                <h4><code>bonus::synchronising</code></h4>
<ul>
<li><s>volatile?</s></li>
<li>atomic_T / std::atomic<T></li>
<li><code>std::atomic&lt;T&gt;::is_always_lock_free</code></li>
</ul>

            </section>
        
            <section >
                <h4><code>bonus::synchronising</code></h4>
<ul>
<li><s>volatile?</s></li>
<li>atomic_T / std::atomic<T></li>
<li><code>std::atomic&lt;T&gt;::is_always_lock_free</code></li>
<li><code>cpsid / cpsie</code></li>
</ul>

            </section>
        

    </section>
    



    
    <section>
        <section >
            <h4><code>bonus::freeRTOS</code></h4>

            </section>
        
            <section >
                <h4><code>bonus::freeRTOS</code></h4>
<ul>
<li><code>ulTaskNotifyTake()</code></li>
<li><code>xTaskNotifyGive()</code></li>
<li><code>vTaskNotifyGiveFromISR()</code></li>
<li><a href="https://embeddedartistry.com/blog/2018/05/28/freertos-task-notifications-a-lightweight-method-for-waking-threads/">https://embeddedartistry.com/blog/2018/05/28/freertos-task-notifications-a-lightweight-method-for-waking-threads/</a></li>
</ul>
<aside class="notes"> create coroutine task, sleep until notified from ISR</aside>

            </section>
        

    </section>
    



    
        <section >
            
            <h4><code>bonus::interruptVectorTable</code></h4>

            </section>
    



    
        <section >
            
            <h4><code>bonus::interruptVectorTable</code></h4>
<p>startup asm</p>
<pre><code>.word  _estack
.word  Reset_Handler

.word  NMI_Handler
.word  HardFault_Handler
.word  MemManage_Handler
.word  BusFault_Handler
.word  UsageFault_Handler
.word  0
.word  0
.word  0
.word  0
.word  SVC_Handler
...
</code></pre>
<aside class="notes"> startup assembly - vector table defined in memory - handler functions placed at these addresses</aside>

            </section>
    



    
        <section >
            
            <h4><code>bonus::interruptVectorTable</code></h4>
<p>gaps</p>
<pre><code>.word     DCMI_IRQHandler           /* DCMI     */
.word     0                         /* Reserved */
.word     0                         /* Reserved */
.word     FPU_IRQHandler            /* FPU      */
.word     0                         /* Reserved */
.word     0                         /* Reserved */
.word     SPI4_IRQHandler           /* SPI4     */
.word     0                         /* Reserved */
.word     0                         /* Reserved */
.word     SAI1_IRQHandler           /* SAI1     */
.word     0                         /* Reserved */
.word     0                         /* Reserved */
...
</code></pre>
<aside class="notes"> reserved gaps may still be internally connected - might be possible to use these</aside>

            </section>
    



    
        <section >
            
            <h4><code>bonus::interruptVectorTable</code></h4>
<p>task handlers</p>
<pre><code>.word     DCMI_IRQHandler           /* DCMI     */
.word     taskA_Handler             /* Reserved */
.word     taskB_Handler             /* Reserved */
.word     FPU_IRQHandler            /* FPU      */
.word     taskC_Handler             /* Reserved */
.word     0                         /* Reserved */
.word     SPI4_IRQHandler           /* SPI4     */
.word     0                         /* Reserved */
.word     0                         /* Reserved */
.word     SAI1_IRQHandler           /* SAI1     */
.word     0                         /* Reserved */
.word     0                         /* Reserved */
...
</code></pre>
<aside class="notes"> task handlers directly in the table - no need to use timers</aside>

            </section>
    


    </div>


  </div>

  <div class="line top"></div>
  <div class="line bottom"></div>
  <div class="line left"></div>
  <div class="line right"></div>

  <script src="libs/reveal.js/4.3.1/reveal.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/notes/notes.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/markdown/markdown.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/highlight/highlight.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/math/math.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/fullscreen/plugin.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/animate/plugin.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/animate/svg.min.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/anything/plugin.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/anything/Chart.min.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/anything/d3/d3.v3.min.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/anything/d3.patch.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/anything/d3/queue.v1.min.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/anything/d3/topojson.v1.min.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/anything/function-plot.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/customcontrols/plugin.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/embed-tweet/plugin.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/chart/chart.min.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/chart/plugin.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/verticator/verticator.js"></script>

<script src="libs/reveal.js/4.3.1/plugin/zoom/zoom.js"></script>
<script src="libs/reveal.js/4.3.1/plugin/search/search.js"></script>

<script src="libs/reveal.js/4.3.1/plugin/chalkboard/plugin.js"></script>

<!--	<script src="libs/reveal.js/4.3.1/plugin/audio-slideshow/plugin.js"></script>  -->
<!--	<script src="libs/reveal.js/4.3.1/plugin/audio-slideshow/recorder.js"></script>-->
<!--	<script src="libs/reveal.js/4.3.1/plugin/audio-slideshow/RecordRTC.js"></script>-->

  

<script>
  const printPlugins = [
      RevealNotes,
      RevealHighlight,
      RevealMath.MathJax3,
      RevealAnimate,
      RevealChalkboard, 
			RevealEmbedTweet,
			RevealChart,
		];

		const plugins =  [...printPlugins,
		RevealZoom, 
		RevealSearch, 
				RevealMarkdown, 
				
				RevealFullscreen,
				RevealAnything,
				//RevealAudioSlideshow,
				//RevealAudioRecorder,
				
				// poll
				// question
				// seminar
				Verticator 
				 ]


		// Also available as an ES module, see:
		// https://revealjs.com/initialization/
		Reveal.initialize({
			controls: true,
      controlsTutorial: true,
      controlsLayout: 'bottom-right',
      controlsBackArrows: 'faded',
      progress: true,
      slideNumber: false,
      //#showSlideNumber "all" "print" "speaker"
      hash: true, //# hash: false,
      //# respondToHashChanges: true,
      //# history: false,
      keyboard: true,
      //#keyboardCondition: null,
      overview: true,
      center: true,
      touch: true,
      loop: false,
      rtl: false,
      //#navigationMode: 'default', linear grid
      shuffle: false,
      fragments: true,
      fragmentInURL: false,
      embedded: false,
      help: true,
      //#pause: true
      showNotes: false,
      autoPlayMedia: false, // TODO fix this to a nullable value
      //#preloadIframes: null. true false
      //#autoAnimate: true
      //#autoAnimateMatcher: null,
      //#autoAnimateEasing: 'ease',
      //autoAnimateDuration: 1.0,
      //#autoAnimateUnmatched: true
      //#autoAnimateStyles: []
      autoSlide: 0, // TODO fix this to a falseable value
      autoSlideStoppable: true,
      autoSlideMethod: '0',
      defaultTiming: 120,
      mouseWheel: false,
      //#previewLinks: false
      //#postMessage: true, // TODO : this can cause issues with the vscode api ???
      //#postMessageEvents: false,
      //#focusBodyOnPageVisibilityChange: true,
      transition: 'fade',
      transitionSpeed: 'default',
      backgroundTransition: 'fade',
      //#pdfMaxPagesPerSlide: Number.POSITIVE_INFINITY,
      //#pdfSeparateFragments: true,
      //#pdfPageHeightOffset: -1,
      viewDistance: 3,
      //#mobileViewDistance: 2,
      display: 'block',
      //#hideInactiveCursor: true,
      //#hideCursorTime: 5000

      // Parallax Background
      parallaxBackgroundImage: '',
      parallaxBackgroundSize: '',
      parallaxBackgroundHorizontal: 0,
      parallaxBackgroundVertical: 0,

      //Presentation Size
      width: 960,
			height: 700,
			margin: 0.04,
      minScale: 0.2,
      maxScale: 2,
      disableLayout: false,

      audio: {
        prefix: 'audio/', // audio files are stored in the "audio" folder
        suffix: '.ogg', // audio files have the ".ogg" ending
        textToSpeechURL: null, // the URL to the text to speech converter
        defaultNotes: false, // use slide notes as default for the text to speech converter
        defaultText: false, // use slide text as default for the text to speech converter
        advance: 0, // advance to next slide after given time in milliseconds after audio has played, use negative value to not advance
        autoplay: false, // automatically start slideshow
        defaultDuration: 5, // default duration in seconds if no audio is available
        defaultAudios: true, // try to play audios with names such as audio/1.2.ogg
        playerOpacity: 0.05, // opacity value of audio player if unfocused
        playerStyle: 'position: fixed; bottom: 4px; left: 25%; width: 50%; height:75px; z-index: 33;', // style used for container of audio controls
        startAtFragment: false, // when moving to a slide, start at the current fragment or at the start of the slide
      },
      
      chalkboard: { // font-awesome.min.css must be available
        //src: "chalkboard/chalkboard.json",
        storage: "chalkboard-demo",
      },
      
			customcontrols: {
					controls: [
      						{
						  id: 'toggle-overview',
						  title: 'Toggle overview (O)',
						  icon: '<i class="fa fa-th"></i>',
						  action: 'Reveal.toggleOverview();'
						}
						,
      {
        icon: '<i class="fa fa-pen-square"></i>',
        title: 'Toggle chalkboard (B)',
        action: 'RevealChalkboard.toggleChalkboard();'
      },
      {
        icon: '<i class="fa fa-pen"></i>',
        title: 'Toggle notes canvas (C)',
        action: 'RevealChalkboard.toggleNotesCanvas();'
      }
      
				]
			},
			chart: {
					defaults: { 
						color: 'lightgray', // color of labels
						scale: { 
							beginAtZero: true, 
							ticks: { stepSize: 1 },
							grid: { color: "lightgray" } , // color of grid lines
						},
					},
					line: { borderColor: [ "rgba(20,220,220,.8)" , "rgba(220,120,120,.8)", "rgba(20,120,220,.8)" ], "borderDash": [ [5,10], [0,0] ] }, 
					bar: { backgroundColor: [ "rgba(20,220,220,.8)" , "rgba(220,120,120,.8)", "rgba(20,120,220,.8)" ]}, 
					pie: { backgroundColor: [ ["rgba(0,0,0,.8)" , "rgba(220,20,20,.8)", "rgba(20,220,20,.8)", "rgba(220,220,20,.8)", "rgba(20,20,220,.8)"] ]},
					radar: { borderColor: [ "rgba(20,220,220,.8)" , "rgba(220,120,120,.8)", "rgba(20,120,220,.8)" ]}, 
			},
			math: {
				mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
				config: 'TeX-AMS_HTML-full',
				// pass other options into `MathJax.Hub.Config()`
				TeX: { Macros: { RR: "{\\bf R}" } }
				},
				anything: [ 
				{
		className: "plot",
		defaults: {width:500, height: 500, grid:true},
		initialize: (function(container, options){ options.target = "#"+container.id; functionPlot(options) })
	 },
	 {
		className: "chart",  
		initialize: (function(container, options){ container.chart = new Chart(container.getContext("2d"), options);  })
	 },
	 {
		className: "anything",
		initialize: (function(container, options){ if (options && options.initialize) { options.initialize(container)} })
	 },
					],
			// Learn about plugins: https://revealjs.com/plugins/
			plugins: (window.location.search.match(/print-pdf/gi) ? printPlugins : plugins ) 
		});
			


	    // Change chalkboard theme : 
		function changeTheme(input) {
			var config = {};
			config.theme = input.value;
			Reveal.getPlugin("RevealChalkboard").configure(config);
			input.blur();
		}

		// // Handle the message inside the webview
        // window.addEventListener('message', event => {

        //     const message = event.data; // The JSON data our extension sent

        //     switch (message.command) {
        //         case 'refactor':
        //             Reveal.toggleHelp();
        //     }
        // });

		if (window.location.search.match(/print-pdf-now/gi)) {
      		setTimeout(() => {
				window.print();
			  }, 2500);
			
    }
</script>

</body>

</html>